{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b2/6c7545bb7a38754d63048c7696804a0d947328125d81bf12beaa692c3ae3/numpy-1.19.5-cp36-cp36m-manylinux1_x86_64.whl (13.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.4MB 2.9MB/s eta 0:00:01  8% |██▋                             | 1.1MB 17.8MB/s eta 0:00:01    32% |██████████▍                     | 4.4MB 21.1MB/s eta 0:00:01    56% |██████████████████              | 7.5MB 20.6MB/s eta 0:00:01    64% |████████████████████▌           | 8.6MB 23.1MB/s eta 0:00:01    71% |███████████████████████         | 9.6MB 21.8MB/s eta 0:00:01    86% |███████████████████████████▉    | 11.6MB 16.7MB/s eta 0:00:01    93% |██████████████████████████████  | 12.6MB 21.0MB/s eta 0:00:01\n",
      "\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "Successfully installed numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "! pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/12/18eda60a1b961e0248e1b1e3ec1ff417420596dc7edf3614ef58a7a8cf6a/setuptools-54.1.2-py3-none-any.whl (785kB)\n",
      "\u001b[K    100% |████████████████████████████████| 788kB 7.8MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Found existing installation: setuptools 38.4.0\n",
      "    Uninstalling setuptools-38.4.0:\n",
      "      Successfully uninstalled setuptools-38.4.0\n",
      "Successfully installed setuptools-54.1.2\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/ef/60d7ba03b5c442309ef42e7d69959f73aacccd0d86008362a681c4698e83/pip-21.0.1-py3-none-any.whl (1.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 11.5MB/s ta 0:00:01    47% |███████████████▎                | 737kB 20.2MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 18.1\n",
      "    Uninstalling pip-18.1:\n",
      "      Successfully uninstalled pip-18.1\n",
      "Successfully installed pip-21.0.1\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 157.5 MB 25 kB/s s eta 0:00:01  |▎                               | 1.2 MB 5.4 MB/s eta 0:00:29     |▊                               | 3.8 MB 5.4 MB/s eta 0:00:29     |██                              | 9.8 MB 5.4 MB/s eta 0:00:28     |███▍                            | 16.6 MB 5.4 MB/s eta 0:00:27     |███▋                            | 17.7 MB 5.4 MB/s eta 0:00:26     |███▉                            | 18.9 MB 5.4 MB/s eta 0:00:26     |████▉                           | 23.6 MB 24.4 MB/s eta 0:00:06     |█████                           | 24.6 MB 24.4 MB/s eta 0:00:06     |██████                          | 30.0 MB 24.4 MB/s eta 0:00:06     |███████▉                        | 38.5 MB 24.4 MB/s eta 0:00:05     |████████▎                       | 40.9 MB 24.4 MB/s eta 0:00:05     |████████▌                       | 42.0 MB 24.4 MB/s eta 0:00:05     |████████▉                       | 43.2 MB 24.1 MB/s eta 0:00:05     |█████████                       | 44.4 MB 24.1 MB/s eta 0:00:05     |█████████▎                      | 45.6 MB 24.1 MB/s eta 0:00:05     |██████████▎                     | 50.6 MB 24.1 MB/s eta 0:00:05     |██████████▌                     | 51.7 MB 24.1 MB/s eta 0:00:05     |██████████▊                     | 52.8 MB 24.1 MB/s eta 0:00:05     |███████████▋                    | 57.0 MB 24.1 MB/s eta 0:00:05     |████████████▎                   | 60.2 MB 24.1 MB/s eta 0:00:05     |████████████▉                   | 63.3 MB 22.1 MB/s eta 0:00:05     |█████████████                   | 64.4 MB 22.1 MB/s eta 0:00:05     |█████████████▊                  | 67.7 MB 22.1 MB/s eta 0:00:05     |██████████████▏                 | 69.9 MB 22.1 MB/s eta 0:00:04     |██████████████▍                 | 71.0 MB 22.1 MB/s eta 0:00:04     |██████████████▊                 | 72.2 MB 22.1 MB/s eta 0:00:04     |███████████████▏                | 74.4 MB 22.1 MB/s eta 0:00:04     |███████████████▍                | 75.5 MB 22.1 MB/s eta 0:00:04     |███████████████▋                | 76.7 MB 22.1 MB/s eta 0:00:04     |███████████████▉                | 77.8 MB 22.1 MB/s eta 0:00:04     |████████████████                | 78.9 MB 22.1 MB/s eta 0:00:04     |████████████████▎               | 80.1 MB 22.1 MB/s eta 0:00:04     |████████████████▌               | 81.2 MB 22.1 MB/s eta 0:00:04     |█████████████████               | 83.5 MB 22.1 MB/s eta 0:00:04     |██████████████████▎             | 90.2 MB 22.6 MB/s eta 0:00:03     |██████████████████▋             | 91.3 MB 22.6 MB/s eta 0:00:03     |███████████████████             | 93.5 MB 22.6 MB/s eta 0:00:03     |███████████████████▎            | 94.8 MB 22.6 MB/s eta 0:00:03     |███████████████████▊            | 97.1 MB 22.6 MB/s eta 0:00:03     |████████████████████▍           | 100.4 MB 22.6 MB/s eta 0:00:03     |████████████████████▋           | 101.5 MB 22.6 MB/s eta 0:00:03     |████████████████████▉           | 102.7 MB 22.6 MB/s eta 0:00:03     |█████████████████████▏          | 104.1 MB 22.6 MB/s eta 0:00:03     |█████████████████████▋          | 106.3 MB 19.7 MB/s eta 0:00:03     |██████████████████████          | 108.7 MB 19.7 MB/s eta 0:00:03     |██████████████████████▎         | 109.8 MB 19.7 MB/s eta 0:00:03     |██████████████████████▌         | 111.0 MB 19.7 MB/s eta 0:00:03     |██████████████████████▊         | 112.0 MB 19.7 MB/s eta 0:00:03     |███████████████████████         | 113.3 MB 19.7 MB/s eta 0:00:03     |███████████████████████▎        | 114.4 MB 19.7 MB/s eta 0:00:03     |███████████████████████▉        | 117.1 MB 19.7 MB/s eta 0:00:03     |████████████████████████        | 118.5 MB 19.7 MB/s eta 0:00:02     |████████████████████████▍       | 119.8 MB 19.7 MB/s eta 0:00:02     |████████████████████████▋       | 121.2 MB 19.7 MB/s eta 0:00:02     |█████████████████████████       | 122.6 MB 19.7 MB/s eta 0:00:02     |█████████████████████████▍      | 125.0 MB 19.7 MB/s eta 0:00:02     |█████████████████████████▊      | 126.4 MB 19.7 MB/s eta 0:00:02     |██████████████████████████▏     | 128.6 MB 21.0 MB/s eta 0:00:02     |██████████████████████████▍     | 130.0 MB 21.0 MB/s eta 0:00:02     |██████████████████████████▋     | 131.1 MB 21.0 MB/s eta 0:00:02     |██████████████████████████▉     | 131.8 MB 21.0 MB/s eta 0:00:02     |███████████████████████████     | 133.1 MB 21.0 MB/s eta 0:00:02     |███████████████████████████▎    | 134.4 MB 21.0 MB/s eta 0:00:02     |███████████████████████████▌    | 135.5 MB 21.0 MB/s eta 0:00:02     |███████████████████████████▉    | 136.8 MB 21.0 MB/s eta 0:00:01     |████████████████████████████    | 138.2 MB 21.0 MB/s eta 0:00:01     |████████████████████████████▊   | 141.5 MB 21.0 MB/s eta 0:00:01     |█████████████████████████████   | 142.5 MB 21.0 MB/s eta 0:00:01     |█████████████████████████████▏  | 143.8 MB 21.0 MB/s eta 0:00:01     |█████████████████████████████▊  | 146.3 MB 21.0 MB/s eta 0:00:01     |██████████████████████████████  | 147.5 MB 21.0 MB/s eta 0:00:01     |██████████████████████████████▎ | 148.9 MB 21.0 MB/s eta 0:00:01     |███████████████████████████████ | 152.8 MB 21.0 MB/s eta 0:00:01     |███████████████████████████████▌| 155.3 MB 21.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from xgboost) (1.2.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.3.3\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade setuptools\n",
    "! pip install --upgrade pip\n",
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from imbalanced-learn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from imbalanced-learn) (0.11)\n",
      "Collecting scikit-learn>=0.24\n",
      "  Downloading scikit_learn-0.24.1-cp36-cp36m-manylinux2010_x86_64.whl (22.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.2 MB 23.7 MB/s eta 0:00:01   |████▎                           | 3.0 MB 6.5 MB/s eta 0:00:03     |██████████████                  | 9.7 MB 6.5 MB/s eta 0:00:02     |████████████████████████▍       | 16.9 MB 6.5 MB/s eta 0:00:01     |██████████████████████████      | 18.1 MB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from imbalanced-learn) (1.2.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, imbalanced-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.19.1\n",
      "    Uninstalling scikit-learn-0.19.1:\n",
      "      Successfully uninstalled scikit-learn-0.19.1\n",
      "Successfully installed imbalanced-learn-0.8.0 scikit-learn-0.24.1 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "! pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (0.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    "    RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from datetime import datetime\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "mailout_train = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42430\n",
       "1      532\n",
       "Name: RESPONSE, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train['RESPONSE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's an inbalenced problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMEO_DEU_2015 = ['5D' '5B' '2D' '7B' '4C' '5C' nan '3D' '5A' '2C' '4A' '6B' '1A' '8D' '4B'\n",
      " '7A' '4E' '3A' '7C' '9D' '8A' '5E' '8B' '3C' '6E' '4D' '2B' '3B' '7E'\n",
      " '2A' '6C' '1C' '6D' '7D' '1D' '8C' '9A' '9B' '9C' '9E' '6F' '1E' '6A'\n",
      " '5F' '1B' 'XX']\n",
      "CAMEO_DEUG_2015 = [5.0 2.0 7.0 4.0 nan 3.0 6.0 1.0 8.0 9.0 '4' '6' '2' '9' '8' '7' '3' '1'\n",
      " '5' 'X']\n",
      "CAMEO_INTL_2015 = [34.0 32.0 14.0 41.0 24.0 33.0 nan 25.0 31.0 22.0 43.0 13.0 55.0 23.0 54.0\n",
      " 51.0 45.0 12.0 44.0 35.0 15.0 52.0 '23' '44' '14' '55' '51' '45' '43'\n",
      " '22' '54' '24' '25' '13' '12' '35' '33' '41' '15' '52' '31' '32' '34'\n",
      " 'XX']\n",
      "D19_LETZTER_KAUF_BRANCHE = ['D19_UNBEKANNT' 'D19_TELKO_MOBILE' 'D19_LEBENSMITTEL'\n",
      " 'D19_BEKLEIDUNG_GEH' 'D19_BUCH_CD' nan 'D19_NAHRUNGSERGAENZUNG'\n",
      " 'D19_SCHUHE' 'D19_SONSTIGE' 'D19_HAUS_DEKO' 'D19_FREIZEIT' 'D19_ENERGIE'\n",
      " 'D19_VOLLSORTIMENT' 'D19_BANKEN_REST' 'D19_VERSICHERUNGEN'\n",
      " 'D19_KINDERARTIKEL' 'D19_TECHNIK' 'D19_DROGERIEARTIKEL'\n",
      " 'D19_BEKLEIDUNG_REST' 'D19_WEIN_FEINKOST' 'D19_HANDWERK' 'D19_GARTEN'\n",
      " 'D19_BANKEN_DIREKT' 'D19_DIGIT_SERV' 'D19_REISEN' 'D19_SAMMELARTIKEL'\n",
      " 'D19_BANKEN_GROSS' 'D19_VERSAND_REST' 'D19_TELKO_REST' 'D19_BILDUNG'\n",
      " 'D19_BANKEN_LOKAL' 'D19_TIERARTIKEL' 'D19_BIO_OEKO' 'D19_RATGEBER'\n",
      " 'D19_LOTTO' 'D19_KOSMETIK']\n",
      "EINGEFUEGT_AM = ['1992-02-10 00:00:00' '1997-05-14 00:00:00' '1995-05-24 00:00:00' ...\n",
      " '2002-08-28 00:00:00' '2014-03-18 00:00:00' '2003-11-22 00:00:00']\n",
      "OST_WEST_KZ = ['W' 'O' nan]\n"
     ]
    }
   ],
   "source": [
    "for col in mailout_train.dtypes[mailout_train.dtypes == 'object'].index:\n",
    "    print(f'{col} = {mailout_train[col].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CAMEO_DEUG_2015 and CAMEO_INTL_2015 should be numeric, so I will replace the 'X' and 'XX' for -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train['CAMEO_DEUG_2015'] = pd.to_numeric(mailout_train['CAMEO_DEUG_2015'].replace('X', -1))\n",
    "mailout_train['CAMEO_INTL_2015'] = pd.to_numeric(mailout_train['CAMEO_INTL_2015'].replace('XX', -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    367.000000\n",
       "mean       0.140621\n",
       "std        0.126460\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.185327\n",
       "75%        0.185327\n",
       "max        0.999046\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_of_na = mailout_train.isna().sum() / mailout_train.shape[0]\n",
    "percentage_of_na = percentage_of_na.sort_values(ascending=False)\n",
    "percentage_of_na.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a2c649438>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(percentage_of_na);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RT_UEBERGROESSE', 'HH_EINKOMMEN_SCORE', 'CJT_TYP_6', 'CJT_TYP_5',\n",
       "       'LP_FAMILIE_FEIN', 'LP_FAMILIE_GROB', 'RT_SCHNAEPPCHEN',\n",
       "       'LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB', 'LP_STATUS_FEIN',\n",
       "       ...\n",
       "       'D19_VERSAND_REST', 'D19_VERSI_ANZ_12', 'D19_VERSI_ANZ_24',\n",
       "       'D19_VERSI_DATUM', 'D19_VERSI_OFFLINE_DATUM', 'D19_VERSI_ONLINE_DATUM',\n",
       "       'D19_VERSICHERUNGEN', 'D19_VOLLSORTIMENT', 'D19_WEIN_FEINKOST', 'LNR'],\n",
       "      dtype='object', length=115)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_of_na[percentage_of_na < 0.15].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5892649318001956"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_of_na['KK_KUNDENTYP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above columns, I only could find the meaning of KK_KUNDENTYP at Excel spreadsheets, so all other I gonna drop and fill with -1 the nan cells of KK_KUNDENTYP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train['KK_KUNDENTYP'] = mailout_train['KK_KUNDENTYP'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_filtered = mailout_train.drop(['ALTER_KIND4', 'ALTER_KIND3', 'ALTER_KIND2', 'ALTER_KIND1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_filtered[mailout_train_filtered.dtypes[mailout_train_filtered.dtypes == 'object'].index] = mailout_train_filtered[mailout_train_filtered.dtypes[mailout_train_filtered.dtypes == 'object'].index].apply(lambda x: x.fillna(value='-1'))\n",
    "mailout_train_filtered[mailout_train_filtered.dtypes[mailout_train_filtered.dtypes != 'object'].index] = mailout_train_filtered[mailout_train_filtered.dtypes[mailout_train_filtered.dtypes != 'object'].index].apply(lambda x: x.fillna(value=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = mailout_train_filtered.dtypes[mailout_train.dtypes == 'object'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_filtered[obj_cols] = mailout_train_filtered[obj_cols].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is needed because if I try to run the random grid search with the total data a no space left on device error is raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_train_filtered = mailout_train_filtered.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mailout_train_filtered.drop('RESPONSE', axis=1)\n",
    "y = mailout_train_filtered['RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = RobustScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_Regressor = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'lambda': [0, 0.5, 1],\n",
    "        'alpha': [0, 0.5, 1],\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "[CV 1/3] END alpha=1, colsample_bytree=0.8, gamma=1, lambda=0.5, max_depth=4, min_child_weight=1, subsample=0.8; total time= 1.1min\n",
      "[CV 1/3] END alpha=1, colsample_bytree=0.8, gamma=1, lambda=0, max_depth=4, min_child_weight=1, subsample=0.6; total time= 1.1min\n",
      "[CV 2/3] END alpha=1, colsample_bytree=0.8, gamma=1, lambda=0, max_depth=4, min_child_weight=1, subsample=0.6; total time= 1.1min\n",
      "[CV 3/3] END alpha=1, colsample_bytree=0.8, gamma=1, lambda=0, max_depth=4, min_child_weight=1, subsample=0.6; total time= 1.1min\n",
      "[CV 2/3] END alpha=1, colsample_bytree=0.8, gamma=1, lambda=0.5, max_depth=4, min_child_weight=1, subsample=0.8; total time= 1.1min\n",
      "[CV 3/3] END alpha=1, colsample_bytree=0.8, gamma=1, lambda=0.5, max_depth=4, min_child_weight=1, subsample=0.8; total time= 1.1min\n",
      "[CV 2/3] END alpha=0, colsample_bytree=1.0, gamma=5, lambda=1, max_depth=5, min_child_weight=10, subsample=0.8; total time= 1.6min\n",
      "[CV 1/3] END alpha=0, colsample_bytree=1.0, gamma=5, lambda=1, max_depth=5, min_child_weight=10, subsample=0.8; total time= 1.6min\n",
      "[CV 1/3] END alpha=0, colsample_bytree=0.6, gamma=2, lambda=0.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  52.0s\n",
      "[CV 2/3] END alpha=0, colsample_bytree=0.6, gamma=2, lambda=0.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  52.3s\n",
      "[CV 3/3] END alpha=0, colsample_bytree=0.6, gamma=2, lambda=0.5, max_depth=4, min_child_weight=10, subsample=0.8; total time=  52.4s\n",
      "[CV 3/3] END alpha=0, colsample_bytree=1.0, gamma=5, lambda=1, max_depth=5, min_child_weight=10, subsample=0.8; total time= 1.6min\n",
      "[CV 1/3] END alpha=1, colsample_bytree=1.0, gamma=5, lambda=0.5, max_depth=3, min_child_weight=10, subsample=0.8; total time= 1.0min\n",
      "[CV 1/3] END alpha=0, colsample_bytree=0.6, gamma=1.5, lambda=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=  47.8s\n",
      "[CV 2/3] END alpha=1, colsample_bytree=1.0, gamma=5, lambda=0.5, max_depth=3, min_child_weight=10, subsample=0.8; total time=  59.7s\n",
      "[CV 3/3] END alpha=1, colsample_bytree=1.0, gamma=5, lambda=0.5, max_depth=3, min_child_weight=10, subsample=0.8; total time=  60.0s\n",
      "[CV 2/3] END alpha=0, colsample_bytree=0.6, gamma=1.5, lambda=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=  48.9s\n",
      "[CV 3/3] END alpha=0, colsample_bytree=0.6, gamma=1.5, lambda=1, max_depth=4, min_child_weight=1, subsample=1.0; total time=  47.4s\n",
      "[CV 1/3] END alpha=0.5, colsample_bytree=0.8, gamma=5, lambda=0.5, max_depth=5, min_child_weight=10, subsample=0.8; total time= 1.1min\n",
      "[CV 2/3] END alpha=0.5, colsample_bytree=0.8, gamma=5, lambda=0.5, max_depth=5, min_child_weight=10, subsample=0.8; total time= 1.1min\n",
      "[CV 3/3] END alpha=0.5, colsample_bytree=0.8, gamma=5, lambda=0.5, max_depth=5, min_child_weight=10, subsample=0.8; total time=  54.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7f89d795ad00>,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=...\n",
       "                                          reg_lambda=None,\n",
       "                                          scale_pos_weight=None, subsample=None,\n",
       "                                          tree_method=None,\n",
       "                                          validate_parameters=None,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=7, n_jobs=4,\n",
       "                   param_distributions={'alpha': [0, 0.5, 1],\n",
       "                                        'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'lambda': [0, 0.5, 1],\n",
       "                                        'max_depth': [3, 4, 5],\n",
       "                                        'min_child_weight': [1, 5, 10],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=1001, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 3\n",
    "param_comb = 7\n",
    "\n",
    "strati_kf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 42)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb_Regressor, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=strati_kf.split(X,y), verbose=3, random_state=42)\n",
    "\n",
    "random_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best params were :{'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 4, 'lambda': 0.5, 'gamma': 1, 'colsample_bytree': 0.8, 'alpha': 1} with a score of 0.7371374276654185\n"
     ]
    }
   ],
   "source": [
    "print(f'the best params were :{random_search.best_params_} with a score of {random_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = XGBRegressor(subsample=0.8, min_child_weight=1, max_depth=4, gamma=1, colsample_bytree=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1.0, gamma=1, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=1, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = xgb_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7401558394491257\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_val, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "mailout_test = pd.read_csv('../../data/Term2/capstone/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test['KK_KUNDENTYP'] = mailout_test['KK_KUNDENTYP'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test['CAMEO_DEUG_2015'] = pd.to_numeric(mailout_test['CAMEO_DEUG_2015'].replace('X', -1))\n",
    "mailout_test['CAMEO_INTL_2015'] = pd.to_numeric(mailout_test['CAMEO_INTL_2015'].replace('XX', -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test[mailout_test.dtypes[mailout_test.dtypes == 'object'].index] = mailout_test[mailout_test.dtypes[mailout_test.dtypes == 'object'].index].apply(lambda x: x.fillna(value='-1'))\n",
    "mailout_test[mailout_test.dtypes[mailout_test.dtypes != 'object'].index] = mailout_test[mailout_test.dtypes[mailout_test.dtypes != 'object'].index].apply(lambda x: x.fillna(value=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test = mailout_test.drop(['ALTER_KIND4', 'ALTER_KIND3', 'ALTER_KIND2', 'ALTER_KIND1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols = mailout_test.dtypes[mailout_test.dtypes == 'object'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test[obj_cols] = mailout_test[obj_cols].apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = RobustScaler().fit_transform(mailout_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_test = pipe.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_test[y_preds_test < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_test[y_preds_test > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = mailout_test[['LNR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "response['RESPONSE'] = y_preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.to_csv('response3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
